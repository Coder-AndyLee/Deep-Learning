# 1. 模型评估和验证

## 1. 测试
1. 回归返回的是数值，分类返回的是状态。
2. 训练集 / 测试集划分
```
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X , y , test_size = 0.1)
# 10% data for test set
```
## 2. 混淆矩阵(Confusion Matrix)

![confusion]($res/confusion.png)

## 3. 精确度(Accuracy)
- 正确分类数据占所有数据的百分比。
$$
Accuracy = \frac{True Positive + True Negative}{all data}
$$
```
from sklearn.metrics import accuracy_score
accuracy_score(y_true , y_pred)
```
## 4. 回归指标
1. 平均绝对误差(Mean Absolute Error)：对所有数据到模型的距离的**绝对值**求和。
	- 缺点：绝对值不可微分，不利于梯度下降。

![mean_absolute_error 2]($res/mean_absolute_error%202.png)

```
# 以 LinearRegression 为例
from sklearn.metrics import mean_absolute_error
from sklearn.linear_model import LinearRegression

classifier = LinearRegression()
classifier.fit(X,y)

guesses = classifier.predict(X)

error = mean_absolute_error(y , guesses) # 平均绝对误差
```
2. 均方误差(Mean Squared Error)：对所有数据到模型的距离的**平方**求和。

![mean_squared_error 2]($res/mean_squared_error%202.png)

```
from sklearn.metrics import mean_squared_error

error = mean_squared_error(y , guesses) # 均方误差
```
3. R2 Score
- 简单模型，对数据点求均值$y_0$，得到简单模型 $y = y_0$，
则$R2 Score = 1-\frac{模型的均方误差}{简单模型的均方误差}$ 
- 模型的均方误差总小于简单模型的均方误差
- Bad model : R2 Score should be close to 0 (模型与简单模型的差异小)
- Good model : R2 Score should be close to 1 (模型与简单模型的差异大)

![r2_score 2]($res/r2_score%202.png)

```
from sklearn.metrics import r2_score

y_true = [1, 2, 4]
y_pred = [1.3, 2.5 ,3.7]

r2_score(y_true, y_pred)
```
4. 错误类型
- underfitting : error due to bias.
- overfitting : error due to variance.

5. 模型复杂性图表(Model Complexity Graph)

![Model_Complexity_Graph 2](https://github.com/Coder-AndyLee/Deep-Learning/blob/master/DeepLearning%20-%20Udacity/2.%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.resource/Model_Complexity_Graph.png)

- 上图的做法是错误的，因为使用了test data去训练模型 / 判断模型选用。
- 交叉验证集(Cross Validation Set)：使用Cross Validation Set去决定模型的选用

![cross 2](https://github.com/Coder-AndyLee/Deep-Learning/tree/master/DeepLearning%20-%20Udacity/2.%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.resource/cross.png)


# 2. 卷积神经网络
## 1. 统计不变性
1. 平移不变性：所识别的对象无论在图片/文本的哪个位置，都是一样的。
2. 权重共享(Weight Sharing)：当知道两个输入可能包含相同信息时，可以让它们共享权重，并利用这些输入共同训练权重。
3. 统计不变量：基本上不会随时间或空间改变的事物。

## 2. 卷积网络(ConvNet)
1. ConvNet 是一种空间上共享参数的神经网络
2. 术语
	- Width,Height : 图片 / 滤波器 的width和height
	- Depth / Channel : 和filter数一致
	- Convolution
	- Patch / Kernel ： 单个filter扫描的大小  
	- Valid padding ： 扫描从不超过图像边界
	- Same padding ： 在边界外用0填充
	- 因为得到目标图像的大小是由filter截取部分加权计算得到，所以valid padding的计算次数是少于same padding的；所以valid padding得到的图片要比原图小，而same padding得到的和原图一样。
3. 滤波器 Filter

![cnn]($res/cnn.png)

- Stride（步长） ： 滤波器滑动的间隔。增大 stride 值后，会减少每层总 patch 数量，因此也减小了模型大小。通常这也会降低图像精度。











